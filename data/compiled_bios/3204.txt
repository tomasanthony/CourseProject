 Benjamin Peherstorfer | Courant Institute of Mathematical Sciences, New York University HOME RESEARCH GROUP CODE PUBLICATIONS Benjamin Peherstorfer Assistant Professor in Department of Computer Science Courant Institute of Mathematical Sciences New York University 251 Mercer Street New York, NY 10012 E-mail: pehersto at cims dot nyu dot edu Phone: 212 998 3297 Room: Warren Weaver Hall (WWH), Room 421 Download short bio News Feb 2019 : Our minisymposium " Model Reduction for Problems with Strong Convection, Sharp Gradients, and Discontinuities " (co-organized with Maciej Balajewicz and Gerrit Welper) at the SIAM Conference on Computational Science and Engineering 2019 has been selected as a Featured Minisymposium. Nov 2018 : Invited to give a presentation in the Applied Mathematics Colloquium at Columbia University . Nov 2018 : Invited to give a presentation in the SSD Seminar Series at the Aachen Institute for Advanced Study in Computational Engineering Science (AICES) , RWTH Aachen . Oct 2018 : Invited to give a presentation in the seminar of the Mathematics in Computational Science and Engineering group at EPFL . Sep 2018 : I will join Courant Institute of Mathematical Sciences at New York University as assistant professor on September 1, 2018. Sep 2018 : Invited to speak in the program "Science at Extreme Scales: Where Big Data Meets Large-Scale Computing" at the Institute for Pure & Applied Mathematics (IPAM). Expand Jul 2018 : I have been invited to participate as a Research Fellow in the program Model and dimension reduction in uncertain and dynamic systems at the Institute for Computational and Experimental Research in Mathematics (ICERM) at Brown University in Spring 2020 Apr 2018 : Co-organizer of minisymposium on multilevel and multifidelity methods for Bayesian inverse problems at SIAM Uncertainty Quantification 2018 ; with Tiangang Cui (Monash University) Apr 2018 : Invited speaker at the Model Reduction of Parametrized Systems (MoRePaS) IV conference Mar 2018 : Invited to speak at the workshop " Reducing dimensions and cost for UQ in complex systems ", which is held at the Isaac Newton Institute for Mathematical Sciences Sep 2017 : Our survey paper on multifidelity methods for outer-loop applications has been accepted by SIAM Review Jul 2017 : Our work on data-driven nonintrusive model reduction with operator inference is cited in SIAM News Jul 2017 : Invited to speak at the workshop Quantification of Uncertainty: Improving Efficiency and Technology that is organized by Marta D'Elia (Sandia), Max Gunzburger (Florida State), and Gianluigi Rozza (SISSA) Apr 2017 : Presentation in the colloquium of the Department of Mathematics at Virginia Tech Mar 2017 : Invited presentation at the workshop Uncertainty Quantification and Data-Driven Modeling that is organized by James R. Stewart (Sandia) and Krishna Garikipati (UMich) Feb 2017 : Co-organizer of minisymposium on surrogate modeling at SIAM Computational Science and Engineering 2017; with Gianluigi Rozza (SISSA) Jan 2017 : I became an affiliate of the Wisconsin Institute for Discovery/Optimization Oct 2016 : Presentation in the Applied and Computational Mathematics Seminar at University of Wisconsin-Madison Aug 2016 : I started as Assistant Professor at University of Wisconsin-Madison. Aug 2016 : Invited presentation at workshop on Next Generation Mobility Modeling and Simulation , UW-Madison Jul 2016 : Co-organizer of minisymposium on model reduction at SIAM Annual Meeting 2016 Mar 2016 : Co-organizer of the workshop on data-driven model reduction and machine learning Nov 2015 : Invited talk in the seminar series of the Transregional Collaborative Research Center on Invasive Computing Mar 2015 : Co-organizer of minisymposium on adaptive model reduction at SIAM CSE 15 Dec 2014 : I was awarded the Heinz Schwrtzel prize for my PhD thesis Dec 2014 : Invited talk in the scientific computing colloquium at TUM Apr 2014 : Co-organizer of minisymposium on density estimation at SIAM UQ 14 Jan 2014 : Started as Postdoctoral Associate in the group of Karen Willcox at MIT. Sep 2013 : Co-organizer of the workshop on adapt./local. MOR with machine learning Selected preprints of submitted articles [ 1 ] Peherstorfer, B. Model reduction for transport-dominated problems via online adaptive bases and adaptive sampling . arXiv:1812.02094 , 2018 . [ Abstract ] Abstract This work presents a model reduction approach for problems with coherent structures that propagate over time such as convection-dominated flows and wave-type phenomena. Traditional model reduction methods have difficulties with these transport-dominated problems because propagating coherent structures typically introduce high-dimensional features that require high-dimensional approximation spaces. The approach proposed in this work exploits the locality in space and time of propagating coherent structures to derive efficient reduced models. First, full-model solutions are approximated locally in time via local reduced spaces that are adapted with basis updates during time stepping. The basis updates are derived from querying the full model at a few selected spatial coordinates. Second, the locality in space of the coherent structures is exploited via an adaptive sampling scheme that selects at which components to query the full model for computing the basis updates. Our analysis shows that, in probability, the more local the coherent structure is in space, the fewer full-model samples are required to adapt the reduced basis with the proposed adaptive sampling scheme. Numerical results on benchmark examples with interacting wave-type structures and time-varying transport speeds and on a model combustor of a single-element rocket engine demonstrate the wide applicability of our approach and the significant runtime speedups compared to full models and traditional reduced models. [ BibTeX ] @techreport{P18AADEIM, title = {Model reduction for transport-dominated problems via online adaptive bases and adaptive sampling}, author = {Peherstorfer, B.}, journal = {arXiv:1812.02094}, year = {2018}, } [ 2 ] Peherstorfer, B., Drmac, Z. & Gugercin, S. Stabilizing discrete empirical interpolation via randomized and deterministic oversampling . arXiv:1808.10473 , 2018 . [ Abstract ] Abstract This work investigates randomized and deterministic oversampling in (discrete) empirical interpolation for nonlinear model reduction. Empirical interpolation derives approximations of nonlinear terms from a few samples via interpolation in low-dimensional spaces. It has been demonstrated that empirical interpolation can become unstable if the samples from the nonlinear terms are perturbed due to, e.g., noise, turbulence, and numerical inaccuracies. Our probabilistic analysis shows that randomized oversampling stabilizes empirical interpolation in the presence of Gaussian noise. Furthermore, we discuss deterministic oversampling strategies that select points by descending in directions of eigenvectors corresponding to sampling point updates and by establishing connections between sampling point selection and clustering. Our numerical results demonstrate on synthetic and diffusion-reaction problems that randomized and deterministic oversampling with our approach stabilizes empirical interpolation in the presence of noise. [ BibTeX ] @techreport{PDG18ODEIM, title = {Stabilizing discrete empirical interpolation via randomized and deterministic oversampling}, author = {Peherstorfer, B. and Drmac, Z. and Gugercin, S.}, journal = {arXiv:1808.10473}, year = {2018}, } [ 3 ] Peherstorfer, B. & Marzouk, Y. A transport-based multifidelity preconditioner for Markov chain Monte Carlo . arXiv:1808.09379 , 2018 . [ BibTeX ] @techreport{PM18MultiTM, title = {A transport-based multifidelity preconditioner for Markov chain Monte Carlo}, author = {Peherstorfer, B. and Marzouk, Y.}, journal = {arXiv:1808.09379}, year = {2018}, } [ 4 ] Peherstorfer, B. Multifidelity Monte Carlo estimation with adaptive low-fidelity models . University of Wisconsin-Madison , Technical Report , 2017 . [ BibTeX ] @techreport{P17AMFMC, title = {Multifidelity Monte Carlo estimation with adaptive low-fidelity models}, author = {Peherstorfer, B.}, volume = {Technical Report}, year = {2017}, institution = {University of Wisconsin-Madison}, } [ 5 ] Kramer, B., Marques, A., Peherstorfer, B., Villa, U. & Willcox, K. Multifidelity probability estimation via fusion of estimators . Massachusetts Institute of Technology , ACDL TR-2017-3 , 2017 . [ BibTeX ] @techreport{KMPVW17Fusion, title = {Multifidelity probability estimation via fusion of estimators}, author = {Kramer, B. and Marques, A. and Peherstorfer, B. and Villa, U. and Willcox, K.}, volume = {ACDL TR-2017-3}, year = {2017}, institution = {Massachusetts Institute of Technology}, } Full list Selected journal publications [ 1 ] Swischuk, R., Mainini, L., Peherstorfer, B. & Willcox, K. Projection-based model reduction: Formulations for physics-based machine learning . Computers & Fluids , 2018 . (accepted) . [ Abstract ] Abstract This paper considers the creation of parametric surrogate models for applications in science and engineering where the goal is to predict high-dimensional output quantities of interest, such as pressure, temperature and strain fields. The proposed methodology develops a low-dimensional parametrization of these quantities of interest using the proper orthogonal decomposition (POD), and combines this parametrization with machine learning methods to learn the map between the input parameters and the POD expansion coefficients. The use of particular solutions in the POD expansion provides a way to embed physical constraints, such as boundary conditions and other features of the solution that must be preserved. The relative costs and effectiveness of four different machine learning techniquesneural networks, multivariate polynomial regression, k-nearest-neighbors and decision treesare explored through two engineering examples. The first example considers prediction of the pressure field around an airfoil, while the second considers prediction of the strain field over a damaged composite panel. The case studies demonstrate the importance of embedding physical constraints within learned models, and also highlight the important point that the amount of model training data available in an engineering setting is often much less than it is in other machine learning applications, making it essential to incorporate knowledge from physical models. [ BibTeX ] @article{SMPK18PhysicsLearning, title = {Projection-based model reduction: Formulations for physics-based machine learning}, author = {Swischuk, R. and Mainini, L. and Peherstorfer, B. and Willcox, K.}, journal = {Computers & Fluids}, year = {2018}, } [ 2 ] Peherstorfer, B., Kramer, B. & Willcox, K. Multifidelity preconditioning of the cross-entropy method for rare event simulation and failure probability estimation . SIAM/ASA Journal on Uncertainty Quantification , 6 (2) :737-761 , 2018 . [ Abstract ] Abstract Accurately estimating rare event probabilities with Monte Carlo can become costly if for each sample a computationally expensive high-fidelity model evaluation is necessary to approximate the system response. Variance reduction with importance sampling significantly reduces the number of required samples if a suitable biasing density is used. This work introduces a multifidelity approach that leverages a hierarchy of low-cost surrogate models to efficiently construct biasing densities for importance sampling. Our multifidelity approach is based on the cross-entropy method that derives a biasing density via an optimization problem. We approximate the solution of the optimization problem at each level of the surrogate-model hierarchy, reusing the densities found on the previous levels to precondition the optimization problem on the subsequent levels. With the preconditioning, an accurate approximation of the solution of the optimization problem at each level can be obtained from a few model evaluations only. In particular, at the highest level, only few evaluations of the computationally expensive high-fidelity model are necessary. Our numerical results demonstrate that our multifidelity approach achieves speedups of several orders of magnitude in a thermal and a reacting-flow example compared to the single-fidelity cross-entropy method that uses a single model alone. [ BibTeX ] @article{PKW17MFCE, title = {Multifidelity preconditioning of the cross-entropy method for rare event simulation and failure probability estimation}, author = {Peherstorfer, B. and Kramer, B. and Willcox, K.}, journal = {SIAM/ASA Journal on Uncertainty Quantification}, volume = {6}, number = {2}, pages = {737-761}, year = {2018}, } [ 3 ] Peherstorfer, B., Gunzburger, M. & Willcox, K. Convergence analysis of multifidelity Monte Carlo estimation . Numerische Mathematik , 139 (3) :683-707 , 2018 . [ Abstract ] Abstract The multifidelity Monte Carlo method provides a general framework for combining cheap low-fidelity approximations of an expensive high-fidelity model to accelerate the Monte Carlo estimation of statistics of the high-fidelity model output. In this work, we investigate the properties of multifidelity Monte Carlo estimation in the setting where a hierarchy of approximations can be constructed with known error and cost bounds. Our main result is a convergence analysis of multifidelity Monte Carlo estimation, for which we prove a bound on the costs of the multifidelity Monte Carlo estimator under assumptions on the error and cost bounds of the low-fidelity approximations. The assumptions that we make are typical in the setting of similar Monte Carlo techniques. Numerical experiments illustrate the derived bounds. [ BibTeX ] @article{PWK16MFMCAsymptotics, title = {Convergence analysis of multifidelity Monte Carlo estimation}, author = {Peherstorfer, B. and Gunzburger, M. and Willcox, K.}, journal = {Numerische Mathematik}, volume = {139}, number = {3}, pages = {683-707}, year = {2018}, } [ 4 ] Qian, E., Peherstorfer, B., O'Malley, D., Vesselinov, V.V. & Willcox, K. Multifidelity Monte Carlo Estimation of Variance and Sensitivity Indices . SIAM/ASA Journal on Uncertainty Quantification , 6 (2) :683-706 , 2018 . [ Abstract ] Abstract Variance-based sensitivity analysis provides a quantitative measure of how uncertainty in a model input contributes to uncertainty in the model output. Such sensitivity analyses arise in a wide variety of applications and are typically computed using Monte Carlo estimation, but the many samples required for Monte Carlo to be sufficiently accurate can make these analyses intractable when the model is expensive. This work presents a multifidelity approach for estimating sensitivity indices that leverages cheaper low-fidelity models to reduce the cost of sensitivity analysis while retaining accuracy guarantees via recourse to the original, expensive model. This paper develops new multifidelity estimators for variance and for the Sobol' main and total effect sensitivity indices. We discuss strategies for dividing limited computational resources among models and specify a recommended strategy. Results are presented for the Ishigami function and a convection-diffusion-reaction model that demonstrate up to 10x speedups for fixed convergence levels. For the problems tested, the multifidelity approach allows inputs to be definitively ranked in importance when Monte Carlo alone fails to do so. [ BibTeX ] @article{QPOVW17MFGSA, title = {Multifidelity Monte Carlo Estimation of Variance and Sensitivity Indices}, author = {Qian, E. and Peherstorfer, B. and O'Malley, D. and Vesselinov, V.V. and Willcox, K.}, journal = {SIAM/ASA Journal on Uncertainty Quantification}, volume = {6}, number = {2}, pages = {683-706}, year = {2018}, } [ 5 ] Baptista, R., Marzouk, Y., Willcox, K. & Peherstorfer, B. Optimal Approximations of Coupling in Multidisciplinary Models . AIAA Journal , 56 :2412-2428 , 2018 . [ Abstract ] Abstract This paper presents a methodology for identifying important discipline couplings in multicomponent engineering systems. Coupling among disciplines contributes significantly to the computational cost of analyzing a system, and can become particularly burdensome when coupled analyses are embedded within a design or optimization loop. In many cases, disciplines may be weakly coupled, so that some of the coupling or interaction terms can be neglected without significantly impacting the accuracy of the system output. Typical practice derives such approximations in an ad hoc manner using expert opinion and domain experience. This work proposes a new approach that formulates an optimization problem to find a model that optimally balances accuracy of the model outputs with the sparsity of the discipline couplings. An adaptive sequential Monte Carlo sampling-based technique is used to efficiently search the combinatorial model space of different discipline couplings. An algorithm for selecting an optimal model is presented and illustrated in a fire detection satellite model and a turbine engine cycle analysis model. [ BibTeX ] @article{AIAADecouple18Baptista, title = {Optimal Approximations of Coupling in Multidisciplinary Models}, author = {Baptista, R. and Marzouk, Y. and Willcox, K. and Peherstorfer, B.}, journal = {AIAA Journal}, volume = {56}, pages = {2412-2428}, year = {2018}, } [ 6 ] Zimmermann, R., Peherstorfer, B. & Willcox, K. Geometric subspace updates with applications to online adaptive nonlinear model reduction . SIAM Journal on Matrix Analysis and Applications , 39 (1) :234-261 , 2018 . [ Abstract ] Abstract In many scientific applications, including model reduction and image processing, subspaces are used as ansatz spaces for the low-dimensional approximation and reconstruction of the state vectors of interest. We introduce a procedure for adapting an existing subspace based on information from the least-squares problem that underlies the approximation problem of interest such that the associated least-squares residual vanishes exactly. The method builds on a Riemmannian optimization procedure on the Grassmann manifold of low-dimensional subspaces, namely the Grassmannian Rank-One Subspace Estimation (GROUSE). We establish for GROUSE a closed-form expression for the residual function along the geodesic descent direction. Specific applications of subspace adaptation are discussed in the context of image processing and model reduction of nonlinear partial differential equation systems. [ BibTeX ] @article{ZPW17SIMAXManifold, title = {Geometric subspace updates with applications to online adaptive nonlinear model reduction}, author = {Zimmermann, R. and Peherstorfer, B. and Willcox, K.}, journal = {SIAM Journal on Matrix Analysis and Applications}, volume = {39}, number = {1}, pages = {234-261}, year = {2018}, } [ 7 ] Peherstorfer, B., Willcox, K. & Gunzburger, M. Survey of multifidelity methods in uncertainty propagation, inference, and optimization . SIAM Review , 60 (3) :550-591 , 2018 . [ Abstract ] Abstract In many situations across computational science and engineering, multiple computational models are available that describe a system of interest. These different models have varying evaluation costs and varying fidelities. Typically, a computationally expensive high-fidelity model describes the system with the accuracy required by the current application at hand, while lower-fidelity models are less accurate but computationally cheaper than the high-fidelity model. Outer-loop applications, such as optimization, inference, and uncertainty quantification, require multiple model evaluations at many different inputs, which often leads to computational demands that exceed available resources if only the high-fidelity model is used. This work surveys multifidelity methods that accelerate the solution of outer-loop applications by combining high-fidelity and low-fidelity model evaluations, where the low-fidelity evaluations arise from an explicit low-fidelity model (e.g., a simplified physics approximation, a reduced model, a data-fit surrogate, etc.) that approximates the same output quantity as the high-fidelity model. The overall premise of these multifidelity methods is that low-fidelity models are leveraged for speedup while the high-fidelity model is kept in the loop to establish accuracy and/or convergence guarantees. We categorize multifidelity methods according to three classes of strategies: adaptation, fusion, and filtering. The paper reviews multifidelity methods in the outer-loop contexts of uncertainty propagation, inference, and optimization. [ BibTeX ] @article{PWG17MultiSurvey, title = {Survey of multifidelity methods in uncertainty propagation, inference, and optimization}, author = {Peherstorfer, B. and Willcox, K. and Gunzburger, M.}, journal = {SIAM Review}, volume = {60}, number = {3}, pages = {550-591}, year = {2018}, } [ 8 ] Peherstorfer, B., Gugercin, S. & Willcox, K. Data-driven reduced model construction with time-domain Loewner models . SIAM Journal on Scientific Computing , 39 (5) :A2152-A2178 , 2017 . [ Abstract ] Abstract This work presents a data-driven nonintrusive model reduction approach for large-scale time-dependent systems with linear state dependence. Traditionally, model reduction is performed in an intrusive projection-based framework, where the operators of the full model are required either explicitly in an assembled form or implicitly through a routine that returns the action of the operators on a vector. Our nonintrusive approach constructs reduced models directly from trajectories of the inputs and outputs of the full model, without requiring the full-model operators. These trajectories are generated by running a simulation of the full model; our method then infers frequency-response data from these simulated time-domain trajectories and uses the data-driven Loewner framework to derive a reduced model. Only a single time-domain simulation is required to derive a reduced model with the new data-driven nonintrusive approach. We demonstrate our model reduction method on several benchmark examples and a finite element model of a cantilever beam; our approach recovers the classical Loewner reduced models and, for these problems, yields high-quality reduced models despite treating the full model as a black box. [ BibTeX ] @article{PSW16TLoewner, title = {Data-driven reduced model construction with time-domain Loewner models}, author = {Peherstorfer, B. and Gugercin, S. and Willcox, K.}, journal = {SIAM Journal on Scientific Computing}, volume = {39}, number = {5}, pages = {A2152-A2178}, year = {2017}, } [ 9 ] Peherstorfer, B., Kramer, B. & Willcox, K. Combining multiple surrogate models to accelerate failure probability estimation with expensive high-fidelity models . Journal of Computational Physics , 341 :61-75 , 2017 . [ Abstract ] Abstract In failure probability estimation, importance sampling constructs a biasing distribution that targets the failure event such that a small number of model evaluations is sufficient to achieve a Monte Carlo estimate of the failure probability with an acceptable accuracy; however, the construction of the biasing distribution often requires a large number of model evaluations, which can become computationally expensive. We present a mixed multifidelity importance sampling (MMFIS) approach that leverages computationally cheap but erroneous surrogate models for the construction of the biasing distribution and that uses the original high-fidelity model to guarantee unbiased estimates of the failure probability. The key property of our MMFIS estimator is that it can leverage multiple surrogate models for the construction of the biasing distribution, instead of a single surrogate model alone. We show that our MMFIS estimator has a mean-squared error that is up to a constant lower than the mean-squared errors of the corresponding estimators that uses any of the given surrogate models alone---even in settings where no information about the approximation qualities of the surrogate models is available. In particular, our MMFIS approach avoids the problem of selecting the surrogate model that leads to the estimator with the lowest mean-squared error, which is challenging if the approximation quality of the surrogate models is unknown. We demonstrate our MMFIS approach on numerical examples, where we achieve orders of magnitude speedups compared to using the high-fidelity model only. [ BibTeX ] @article{PKW16MixedMFIS, title = {Combining multiple surrogate models to accelerate failure probability estimation with expensive high-fidelity models}, author = {Peherstorfer, B. and Kramer, B. and Willcox, K.}, journal = {Journal of Computational Physics}, volume = {341}, pages = {61-75}, year = {2017}, } [ 10 ] Kramer, B., Peherstorfer, B. & Willcox, K. Feedback Control for Systems with Uncertain Parameters Using Online-Adaptive Reduced Models . SIAM Journal on Applied Dynamical Systems , 16 (3) :1563-1586 , 2017 . [ Abstract ] Abstract We consider control and stabilization for large-scale dynamical systems with uncertain, time-varying parameters. The time-critical task of controlling a dynamical system poses major challenges: Using large-scale models is prohibitive, and accurately inferring parameters can be expensive, too. We address both problems by proposing an offline-online strategy for controlling systems with time-varying parameters. During the offline phase, we use a high-fidelity model to compute a library of optimal feedback controller gains over a sampled set of parameter values. Then, during the online phase, in which the uncertain parameter changes over time, we learn a reduced-order model from system data. The learned reduced-order model is employed within an optimization routine to update the feedback control throughout the online phase. Since the system data naturally reflects the uncertain parameter, the data-driven updating of the controller gains is achieved without an explicit parameter estimation step. We consider two numerical test problems in the form of partial differential equations: a convection--diffusion system, and a model for flow through a porous medium. We demonstrate on those models that the proposed method successfully stabilizes the system model in the presence of process noise. [ BibTeX ] @article{KPW16ControlAdaptROM, title = {Feedback Control for Systems with Uncertain Parameters Using Online-Adaptive Reduced Models}, author = {Kramer, B. and Peherstorfer, B. and Willcox, K.}, journal = {SIAM Journal on Applied Dynamical Systems}, volume = {16}, number = {3}, pages = {1563-1586}, year = {2017}, } [ 11 ] Peherstorfer, B., Willcox, K. & Gunzburger, M. Optimal model management for multifidelity Monte Carlo estimation . SIAM Journal on Scientific Computing , 38 (5) :A3163-A3194 , 2016 . [ Abstract ] Abstract This work presents an optimal model management strategy that exploits multifidelity surrogate models to accelerate the estimation of statistics of outputs of computationally expensive high-fidelity models. Existing acceleration methods typically exploit a multilevel hierarchy of surrogate models that follow a known rate of error decay and computational costs; however, a general collection of surrogate models, which may include projection-based reduced models, data-fit models, support vector machines, and simplified-physics models, does not necessarily give rise to such a hierarchy. Our multifidelity approach provides a framework to combine an arbitrary number of surrogate models of any type. Instead of relying on error and cost rates, an optimization problem balances the number of model evaluations across the high-fidelity and surrogate models with respect to error and costs. We show that a unique analytic solution of the model management optimization problem exists under mild conditions on the models. Our multifidelity method makes occasional recourse to the high-fidelity model; in doing so it provides an unbiased estimator of the statistics of the high-fidelity model, even in the absence of error bounds and error estimators for the surrogate models. Numerical experiments with linear and nonlinear examples show that speedups by orders of magnitude are obtained compared to Monte Carlo estimation that invokes a single model only. [ BibTeX ] @article{Peherstorfer15Multi, title = {Optimal model management for multifidelity Monte Carlo estimation}, author = {Peherstorfer, B. and Willcox, K. and Gunzburger, M.}, journal = {SIAM Journal on Scientific Computing}, volume = {38}, number = {5}, pages = {A3163-A3194}, year = {2016}, } [ 12 ] Peherstorfer, B. & Willcox, K. Data-driven operator inference for nonintrusive projection-based model reduction . Computer Methods in Applied Mechanics and Engineering , 306 :196-215 , 2016 . [ Abstract ] Abstract This work presents a nonintrusive projection-based model reduction approach for full models based on time-dependent partial differential equations. Projection-based model reduction constructs the operators of a reduced model by projecting the equations of the full model onto a reduced space. Traditionally, this projection is intrusive, which means that the full-model operators are required either explicitly in an assembled form or implicitly through a routine that returns the action of the operators on a given vector; however, in many situations the full model is given as a black box that computes trajectories of the full-model states and outputs for given initial conditions and inputs, but does not provide the full-model operators. Our nonintrusive operator inference approach infers approximations of the reduced operators from the initial conditions, inputs, trajectories of the states, and outputs of the full model, without requiring the full-model operators. Our operator inference is applicable to full models that are linear in the state or have a low-order polynomial nonlinear term. The inferred operators are the solution of a least-squares problem and converge, with sufficient state trajectory data, in the Frobenius norm to the reduced operators that would be obtained via an intrusive projection of the full-model operators. Our numerical results demonstrate operator inference on a linear climate model and on a tubular reactor model with a polynomial nonlinear term of third order. [ BibTeX ] @article{Peherstorfer16DataDriven, title = {Data-driven operator inference for nonintrusive projection-based model reduction}, author = {Peherstorfer, B. and Willcox, K.}, journal = {Computer Methods in Applied Mechanics and Engineering}, volume = {306}, pages = {196-215}, year = {2016}, } [ 13 ] Peherstorfer, B. & Willcox, K. Dynamic data-driven model reduction: Adapting reduced models from incomplete data . Advanced Modeling and Simulation in Engineering Sciences , 3 (11) , 2016 . [ Abstract ] Abstract This work presents a data-driven online adaptive model reduction approach for systems that undergo dynamic changes. Classical model reduction constructs a reduced model of a large-scale system in an offline phase and then keeps the reduced model unchanged during the evaluations in an online phase; however, if the system changes online, the reduced model may fail to predict the behavior of the changed system. Rebuilding the reduced model from scratch is often too expensive in time-critical and real-time environments. We introduce a dynamic data-driven adaptation approach that adapts the reduced model from incomplete sensor data obtained from the system during the online computations. The updates to the reduced models are derived directly from the incomplete data, without recourse to the full model. Our adaptivity approach approximates the missing values in the incomplete sensor data with gappy proper orthogonal decomposition. These approximate data are then used to derive low-rank updates to the reduced basis and the reduced operators. In our numerical examples, incomplete data with 30-40 percent known values are sufficient to recover the reduced model that would be obtained via rebuilding from scratch. [ BibTeX ] @article{Peherstorfer16AdaptROM, title = {Dynamic data-driven model reduction: Adapting reduced models from incomplete data}, author = {Peherstorfer, B. and Willcox, K.}, journal = {Advanced Modeling and Simulation in Engineering Sciences}, volume = {3}, number = {11}, year = {2016}, } [ 14 ] Peherstorfer, B., Cui, T., Marzouk, Y. & Willcox, K. Multifidelity Importance Sampling . Computer Methods in Applied Mechanics and Engineering , 300 :490-509 , 2016 . [ Abstract ] Abstract Estimating statistics of model outputs with the Monte Carlo method often requires a large number of model evaluations. This leads to long runtimes if the model is expensive to evaluate. Importance sampling is one approach that can lead to a reduction in the number of model evaluations. Importance sampling uses a biasing distribution to sample the model more efficiently, but generating such a biasing distribution can be difficult and usually also requires model evaluations. A different strategy to speed up Monte Carlo sampling is to replace the computationally expensive high-fidelity model with a computationally cheap surrogate model; however, because the surrogate model outputs are only approximations of the high-fidelity model outputs, the estimate obtained using a surrogate model is in general biased with respect to the estimate obtained using the high-fidelity model. We introduce a multifidelity importance sampling (MFIS) method, which combines evaluations of both the high-fidelity and a surrogate model. It uses a surrogate model to facilitate the construction of the biasing distribution, but relies on a small number of evaluations of the high-fidelity model to derive an unbiased estimate of the statistics of interest. We prove that the MFIS estimate is unbiased even in the absence of accuracy guarantees on the surrogate model itself. The MFIS method can be used with any type of surrogate model, such as projection-based reduced-order models and data-fit models. Furthermore, the MFIS method is applicable to black-box models, i.e., where only inputs and the corresponding outputs of the high-fidelity and the surrogate model are available but not the details of the models themselves. We demonstrate on nonlinear and time-dependent problems that our MFIS method achieves speedups of up to several orders of magnitude compared to Monte Carlo with importance sampling that uses the high-fidelity model only. [ BibTeX ] @article{Peherstorfer16MFIS, title = {Multifidelity Importance Sampling}, author = {Peherstorfer, B. and Cui, T. and Marzouk, Y. and Willcox, K.}, journal = {Computer Methods in Applied Mechanics and Engineering}, volume = {300}, pages = {490-509}, year = {2016}, } [ 15 ] Peherstorfer, B. & Willcox, K. Online Adaptive Model Reduction for Nonlinear Systems via Low-Rank Updates . SIAM Journal on Scientific Computing , 37 (4) :A2123-A2150 , 2015 . [ Abstract ] Abstract This work presents a nonlinear model reduction approach for systems of equations stemming from the discretization of partial differential equations with nonlinear terms. Our approach constructs a reduced system with proper orthogonal decomposition and the discrete empirical interpolation method (DEIM); however, whereas classical DEIM derives a linear approximation of the nonlinear terms in a static DEIM space generated in an offline phase, our method adapts the DEIM space as the online calculation proceeds and thus provides a nonlinear approximation. The online adaptation uses new data to produce a reduced system that accurately approximates behavior not anticipated in the offline phase. These online data are obtained by querying the full-order system during the online phase, but only at a few selected components to guarantee a computationally efficient adaptation. Compared to the classical static approach, our online adaptive and nonlinear model reduction approach achieves accuracy improvements of up to three orders of magnitude in our numerical experiments with time-dependent and steady-state nonlinear problems. The examples also demonstrate that through adaptivity, our reduced systems provide valid approximations of the full-order systems outside of the parameter domains for which they were initially built in the offline phase. [ BibTeX ] @article{Peherstorfer15aDEIM, title = {Online Adaptive Model Reduction for Nonlinear Systems via Low-Rank Updates}, author = {Peherstorfer, B. and Willcox, K.}, journal = {SIAM Journal on Scientific Computing}, volume = {37}, number = {4}, pages = {A2123-A2150}, year = {2015}, } [ 16 ] Peherstorfer, B., Gmez, P. & Bungartz, H.J. Reduced Models for Sparse Grid Discretizations of the Multi-Asset Black-Scholes Equation . Advances in Computational Mathematics , 41 (5) :1365-1389 , 2015 . [ Abstract ] Abstract This work presents reduced models for pricing basket options with the Black-Scholes and the Heston model. Basket options lead to multi-dimensional partial differential equations (PDEs) that quickly become computationally infeasible to discretize on full tensor grids. We therefore rely on sparse grid discretizations of the PDEs, which allow us to cope with the curse of dimensionality to some extent. We then derive reduced models with proper orthogonal decomposition. Our numerical results with the Black-Scholes model show that sufficiently accurate results are achieved while gaining speedups between 80 and 160 compared to the high-fidelity sparse grid model for 2-, 3-, and 4-asset options. For the Heston model, results are presented for a single-asset option that leads to a two-dimensional pricing problem, where we achieve significant speedups with our model reduction approach based on high-fidelity sparse grid models. [ BibTeX ] @article{pehersto15BlackScholes, title = {Reduced Models for Sparse Grid Discretizations of the Multi-Asset Black-Scholes Equation}, author = {Peherstorfer, B. and Gmez, P. and Bungartz, H.J.}, journal = {Advances in Computational Mathematics}, volume = {41}, number = {5}, pages = {1365-1389}, year = {2015}, } [ 17 ] Peherstorfer, B. & Willcox, K. Dynamic Data-Driven Reduced-Order Models . Computer Methods in Applied Mechanics and Engineering , 291 :21-41 , 2015 . [ Abstract ] Abstract Data-driven model reduction constructs reduced-order models of large-scale systems by learning the system response characteristics from data. Existing methods build the reduced-order models in a computationally expensive offline phase and then use them in an online phase to provide fast predictions of the system. In cases where the underlying system properties are not static but undergo dynamic changes, repeating the offline phase after each system change to rebuild the reduced-order model from scratch forfeits the savings gained in the online phase. This paper proposes dynamic reduced-order models that break with this classical but rigid approach. Dynamic reduced-order models exploit the opportunity presented by dynamic sensor data and adaptively incorporate sensor data during the online phase. This permits online adaptation to system changes while circumventing the expensive rebuilding of the model. A computationally cheap adaptation is achieved by constructing low-rank updates to the reduced operators. With these updates and with sufficient and accurate data, our approach recovers the same model that would be obtained by rebuilding from scratch. We demonstrate dynamic reduced-order models on a structural assessment example in the context of real-time decision making. We consider a plate in bending where the dynamic reduced-order model quickly adapts to changes in structural properties and achieves speedups of four orders of magnitude compared to rebuilding a model from scratch. [ BibTeX ] @article{pehersto15dynamic, title = {Dynamic Data-Driven Reduced-Order Models}, author = {Peherstorfer, B. and Willcox, K.}, journal = {Computer Methods in Applied Mechanics and Engineering}, volume = {291}, pages = {21-41}, year = {2015}, } [ 18 ] Peherstorfer, B., Zimmer, S., Zenger, C. & Bungartz, H.J. A Multigrid Method for Adaptive Sparse Grids . SIAM Journal on Scientific Computing , 37 (5) :S51-S70 , 2015 . [ Abstract ] Abstract Sparse grids have become an important tool to reduce the number of degrees of freedom of discretizations of moderately high-dimensional partial differential equations; however, the reduction in degrees of freedom comes at the cost of an almost dense and unconventionally structured system of linear equations. To guarantee overall efficiency of the sparse grid approach, special linear solvers are required. We present a multigrid method that exploits the sparse grid structure to achieve an optimal runtime that scales linearly with the number of sparse grid points. Our approach is based on a novel decomposition of the right-hand sides of the coarse grid equations that leads to a reformulation in so-called auxiliary coefficients. With these auxiliary coefficients, the right-hand sides can be represented in a nodal point basis on low-dimensional full grids. Our proposed multigrid method directly operates in this auxiliary coefficient representation, circumventing most of the computationally cumbersome sparse grid structure. Numerical results on nonadaptive and spatially adaptive sparse grids confirm that the runtime of our method scales linearly with the number of sparse grid points and they indicate that the obtained convergence factors are bounded independently of the mesh width. [ BibTeX ] @article{peherstorfer15htmg, title = {A Multigrid Method for Adaptive Sparse Grids}, author = {Peherstorfer, B. and Zimmer, S. and Zenger, C. and Bungartz, H.J.}, journal = {SIAM Journal on Scientific Computing}, volume = {37}, number = {5}, pages = {S51--S70}, year = {2015}, } [ 19 ] Peherstorfer, B., Butnaru, D., Willcox, K. & Bungartz, H.J. Localized Discrete Empirical Interpolation Method . SIAM Journal on Scientific Computing , 36 (1) :A168-A192 , 2014 . [ Abstract ] Abstract This paper presents a new approach to construct more efficient reduced-order models for nonlinear partial differential equations with proper orthogonal decomposition and the discrete empirical interpolation method (DEIM). Whereas DEIM projects the nonlinear term onto one global subspace, our localized discrete empirical interpolation method (LDEIM) computes several local subspaces, each tailored to a particular region of characteristic system behavior. Then, depending on the current state of the system, LDEIM selects an appropriate local subspace for the approximation of the nonlinear term. In this way, the dimensions of the local DEIM subspaces, and thus the computational costs, remain low even though the system might exhibit a wide range of behaviors as it passes through different regimes. LDEIM uses machine learning methods in the offline computational phase to discover these regions via clustering. Local DEIM approximations are then computed for each cluster. In the online computational phase, machine-learning-based classification procedures select one of these local subspaces adaptively as the computation proceeds. The classification can be achieved using either the system parameters or a low-dimensional representation of the current state of the system obtained via feature extraction. The LDEIM approach is demonstrated for a reacting flow example of an H_2-Air flame. In this example, where the system state has a strong nonlinear dependence on the parameters, the LDEIM provides speedups of two orders of magnitude over standard DEIM. [ BibTeX ] @article{peherstorfer13localized, title = {Localized Discrete Empirical Interpolation Method}, author = {Peherstorfer, B. and Butnaru, D. and Willcox, K. and Bungartz, H.J.}, journal = {SIAM Journal on Scientific Computing}, volume = {36}, number = {1}, pages = {A168-A192}, year = {2014}, } [ 20 ] Peherstorfer, B., Kowitz, C., Pflger, D. & Bungartz, H.J. Selected Recent Applications of Sparse Grids . Numerical Mathematics: Theory, Methods and Applications , 8 (1) :47-77 , 2014 . [ Abstract ] Abstract Sparse grids have become a versatile tool for a vast range of applications reaching from interpolation and numerical quadrature to data-driven problems and uncertainty quantification. We review four selected real-world applications of sparse grids: financial product pricing with the Black-Scholes model, interactive exploration of simulation data with sparse-grid-based surrogate models, analysis of simulation data through sparse grid data mining methods, and stability investigations of plasma turbulence simulations. [ BibTeX ] @article{Peherstorfer14SGReview, title = {Selected Recent Applications of Sparse Grids}, author = {Peherstorfer, B. and Kowitz, C. and Pflger, D. and Bungartz, H.J.}, journal = {Numerical Mathematics: Theory, Methods and Applications}, volume = {8}, number = {1}, pages = {47-77}, year = {2014}, } [ 21 ] Pflger, D., Peherstorfer, B. & Bungartz, H.J. Spatially adaptive sparse grids for high-dimensional data-driven problems . Journal of Complexity , 26 (5) :508-522 , 2010 . [ Abstract ] Abstract Sparse grids allow one to employ grid-based discretization methods in data-driven problems. We present an extension of the classical sparse grid approach that allows us to tackle high-dimensional problems by spatially adaptive refinement, modified ansatz functions, and efficient regularization techniques. The competitiveness of this method is shown for typical benchmark problems with up to 166 dimensions for classification in data mining, pointing out properties of sparse grids in this context. To gain insight into the adaptive refinement and to examine the scope for further improvements, the approximation of non-smooth indicator functions with adaptive sparse grids has been studied as a model problem. As an example for an improved adaptive grid refinement, we present results for an edge-detection strategy. [ BibTeX ] @article{pflueger10spatially, title = {Spatially adaptive sparse grids for high-dimensional data-driven problems}, author = {Pflger, D. and Peherstorfer, B. and Bungartz, H.J.}, journal = {Journal of Complexity}, volume = {26}, number = {5}, pages = {508-522}, year = {2010}, } Full list Five recent talks [ 1 ] Peherstorfer, B. A Multifidelity Cross-Entropy Method for Rare Event Simulation . In SIAM Uncertainty Quantification 2018 , Garden Grove, CA , 2018 . [ 2 ] Peherstorfer, B. Data-Driven Multifidelity Methods for Monte Carlo Estimation . In Model Reduction of Parametrized Systems (MoRePaS) IV , Nantes, France , 2018 . [ 3 ] Peherstorfer, B. Multifidelity Monte Carlo estimation with adaptive low-fidelity models . In Reducing dimensions and cost for UQ in complex systems, Isaac Newton Institute for Mathematical Sciences , Cambridge, UK , 2018 . [ 4 ] Peherstorfer, B. Multifidelity methods for rare event simulation . In European Numerical Mathematics and Advanced Applications (ENUMATH) , Bergen, Norway , 2017 . [ 5 ] Peherstorfer, B. Optimal low-rank updates for online adaptive model reduction with the discrete empirical interpolation method . In Householder Symposium XX on Numerical Linear Algebra , Blacksburg, USA , 2017 . Full list 
