Looking for mathematically strong student who likes to prove theorems and enjoys learning new math techniques. I am interested in the performance analysis and design of computer systems, particularly distributed systems. I work on finding analytical models which capture the important characteristics of a computer system and allow me to redesign the system to improve its performance. I believe that many fundamental conventional wisdoms on which we base system designs are not well understood and sometimes false, leading to inferior designs. My research challenges these age-old beliefs. Here are just a few examples: Thousands of "load balancing" heuristics do exactly that -- they aim to balance the load among the existing hosts. But who said that's neccessarily a good thing? Migration policies for networks of workstations and distributed servers direct jobs to the host with least load. That seems good from the job's perspective, but is it best for the system overall? Given a choice between a single machine with power p , or n identical machines each with power p/n, which would you choose? Migrating active jobs is generally considered too expensive. Killing jobs midway through execution and restarting them from scratch later is even worse! Says who? Ever notice that the "proven best" scheduling policies like SRPT (shortest-remaining-processing-time-first) are never used in practice? There's a fear that the big jobs will starve. Is this true? Half my students work on mathematical techniques to derive theorems such as those above. These techniques include: queueing theory, probability theory, scheduling theory, Markov chains, stochastic processes, Matrix-analytic methods, renewal theory, real analysis, andmore. The other half of my students work on applying these theorems to implement high-performance Web servers, database systems, and distributed supercomputing servers.
