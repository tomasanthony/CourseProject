 Greg Durrett gdurrett@cs.utexas.edu Home Publications Research/Group Teaching Software I am an Assistant Professor in the Department of Computer Science at UT Austin . My research covers a range of topics in statistical natural language processing, including coreference resolution, entity linking, document summarization, and syntactic parsing. Solving these problems lets computers access and transform the information in unstructured text in a structured way. To handle the complexities of natural language, my work involves developing new structured machine learning and deep learning approaches to these problems, as well as devising scalable learning and inference techniques to train models on large datasets. See my research page for more information. Prior to joining UT Austin, I received my Ph.D. from UC Berkeley in 2016, where I was advised by Dan Klein and part of the Berkeley NLP Group . Curriculum Vitae Teaching Spring 2019: CS378: Natural Language Processing Fall 2018: CS388: Natural Language Processing Fall 2017: CS395T: Structured Models for NLP Publications Spherical Latent Spaces for Stable Variational Autoencoders Jiacheng Xu and Greg Durrett. EMNLP 2018 . pdf Effective Use of Context in Noisy Entity Linking David Mueller and Greg Durrett. EMNLP 2018 (short) . pdf Picking Apart Story Salads Su Wang, Eric Holgate, Greg Durrett, and Katrin Erk. EMNLP 2018 . pdf Modeling Semantic Plausibility by Injecting World Knowledge Su Wang, Greg Durrett, and Katrin Erk. NAACL 2018 (short) . pdf Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation Greg Durrett, Jonathan Kummerfeld, Taylor Berg-Kirkpatrick, Rebecca Portnoff, Sadia Afroz, Damon McCoy, Kirill Levchenko, and Vern Paxson. EMNLP 2017 . pdf BibTeX code data Tools for Automated Analysis of Cybercriminal Markets Rebecca Portnoff, Sadia Afroz, Greg Durrett, Jonathan Kummerfeld, Taylor Berg-Kirkpatrick, Damon McCoy, Kirill Levchenko, and Vern Paxson. WWW 2017 . pdf BibTeX code data Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints Greg Durrett, Taylor Berg-Kirkpatrick, and Dan Klein. ACL 2016 . pdf BibTeX system release poster Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks Matthew Francis-Landau, Greg Durrett, and Dan Klein. NAACL 2016 . pdf BibTeX Neural CRF Parsing Greg Durrett and Dan Klein. ACL 2015 . pdf synopsis BibTeX system release slides.key slides.pdf Parsing algorithms like CKY are good at reckoning with discrete syntactic structures and neural networks are good at extracting nonlinear features from inputs. We show that neural networks can be used to score CFG rule productions in a continuous way while we can keep the grammar itself discrete. Disfluency Detection with a Semi-Markov Model and Prosodic Features James Ferguson, Greg Durrett, and Dan Klein. NAACL 2015 . pdf synopsis BibTeX When dealing with spoken language, identifying disfluencies like restarts ("I wentI used to go shopping") is an important prerequisite for figuring out what the speaker intended to say. We show that a semi-Markov conditional random field is well-suited to this task since it can make decisions about entire chunks of the sentence at once, rather than deciding in isolation whether or not each word is disfluent. Features targeting the speaker's prosody (directly in the speech signal) give further performance improvements. A Joint Model for Entity Analysis: Coreference, Typing, and Linking Greg Durrett and Dan Klein. TACL 2014 . pdf synopsis BibTeX system release slides.key slides.pdf Using a graphical modeling framework, we can unify component models for coreference resolution, semantic typing (i.e. named entity recognition), and entity linking to a knowledge base, improving performance on all three tasks by capturing cross-task interactions. Less Grammar, More Features David Hall, Greg Durrett, and Dan Klein. ACL 2014 . pdf errata synopsis BibTeX system release Traditional approaches to syntactic parsing have relied on heavily annotated context-free grammars which maintain a large amount of state during parsing. We show that it is possible to build a high-performance parser with a very simple grammar as long as CFG rule productions are scored in a rich way. Our scoring function inspects the words in the sentence that are dominated by the rule in question; this lets us use a simpler grammar because we're looking at important lexical information directly rather than trying to thread it through CFG states. The paper posted here has updated sentiment analysis results compared to the version in the ACL anthology. In the original version of this paper, we trained and evaluated our system on a slightly different dataset from that of Socher et al. (2013) due to a misunderstanding of their evaluation condition. However, the general conclusions about our system's performance relative to theirs are unchanged. Easy Victories and Uphill Battles in Coreference Resolution Greg Durrett and Dan Klein. EMNLP 2013 . Best Paper Finalist pdf synopsis BibTeX system release slides.key slides.pdf We present a simple model for coreference resolution that primarily exploits surface textual properties to determine if two mentions (like "Barack Obama" and "the president") refer to the same entity. Features in our discriminative model targeting these surface properties (including, for example, the first and last words in an entity reference) manage to capture a wide range of linguistic phenomena important for coreference, such as pronoun agreement and discourse structure. Crucially, our surface features can also pick up on other "extra-linguistic" patterns in the data. As a result, our model outperforms previous work that only uses hand-coded heuristics to target linguistic properties of interest. Decentralized Entity-Level Modeling for Coreference Resolution Greg Durrett, David Hall, and Dan Klein. ACL 2013 . pdf synopsis BibTeX slides.key slides.pdf We present a coreference resolution model that can efficiently represent and infer semantic properties associated with entities. During inference, we propagate semantic information along coreference arcs in a probabilistic way, allowing us to discern that "Clinton" is female if that mention's antecedent is "Hillary Clinton." Unsupervised Transcription of Historical Documents Taylor Berg-Kirkpatrick, Greg Durrett, and Dan Klein. ACL 2013 . pdf synopsis BibTeX system release We present a system for optical character recognition on historical documents produced by printing presses. For each document, we learn (with no supervision) the properties of that document including the specific font used and the darkness with which characters were printed, leading to greater recognition accuracy. Our system dramatically outperforms commercial OCR tools on historical documents, making around half as many errors at the word level. Supervised Learning of Complete Morphological Paradigms Greg Durrett and John DeNero. NAACL 2013 . pdf errata synopsis BibTeX dataset code slides.key slides.pdf We propose a model that can learn how to inflect words (e.g. conjugate verbs, decline nouns) based on labeled examples from Wiktionary. We extract rules that describe how part of a word like the prefix or suffix changes for each possible setting of morphological attributes (person, singular vs. plural, etc.), then learn how to predict which change rules apply to words we've never seen before. The paper posted here differs slightly from the one in the ACL anthology. After submitting the camera-ready copy, we discovered that our Finnish nouns dataset also contained adjectives, due to incorrect assumptions we made when scraping Wiktionary. The paper and accompanying dataset are updated to reflect that our evaluation condition is over both Finnish nouns and adjectives simultaneously. Beyond this modification, the results and their interpretation are unchanged. Syntactic Transfer Using a Bilingual Lexicon Greg Durrett, Adam Pauls, and Dan Klein. EMNLP 2012 . pdf synopsis BibTeX slides.pdf We collect information about the syntactic behavior of English words using a large corpus, then show that this information can be ported to other languages by translating the words using a bilingual dictionary. Having this information helps improve performance of a dependency parser for resource-poor languages where large labeled treebanks are not be available. An Empirical Investigation of Discounting in Cross-Domain Language Models Greg Durrett and Dan Klein. ACL 2011 (short) . pdf synopsis BibTeX slides.pdf We modify a standard technique for estimating n-gram language models to give better performance when those language models are applied to text from other domains. We find this is useful even for domains that only differ very slightly. Show thesis Identifying and Resolving Entities in Text Greg Durrett. Ph.D. Thesis, 2016 pdf Show undergrad research Computational Complexity Analysis of Simple Genetic Programming On Two Problems Modeling Isolated Program Semantics Greg Durrett, Frank Neumann, and Una-May O'Reilly. Foundations of Genetic Algorithms 2011 . pdf arXiv BibTeX A Genetic Algorithm to Minimize Chromatic Entropy Greg Durrett, Muriel Mdard, and Una-May O'Reilly. EvoCOP 2010 pdf SpringerLink BibTeX 
