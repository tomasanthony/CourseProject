 Shay Cohen Lecturer Institute for Language, Cognition and Computation School of Informatics University of Edinburgh Prospective students who might be interested in working with me: please see the note here . About me My broad interests are in the intersection of computational linguistics and statistical learning. I am most interested in predicting structure from text. Such structure underlies natural language at all its levels, from discourse, through semantics to syntax. My current interests, all interacting at some level are: (1) the use of linear algebra for learning statistical models, especially those with hidden variables that are not observed in the data; (2) semantic representations, especially abstract meaning representation, and their applications such as document summarization. In my work I use various statistical learning algorithms and language formalisms, including neural networks, spectral methods, probabilistic grammars and others. Click here for a bio. A demo of our XSum abstractive summarization system from EMNLP 2018 is available here . A demo of our reinforcement learning extractive summarization system from NAACL 2018 is available here . Our work on crime drama in the news: BBC , New Scientist , Scottish Legal , The Register , The Telegraph , Daily Mail , The Scotsman , Scottish Daily Mail , Digital Trends . We released the Rainbow Parser, a parser with spectral learning algorithms (and EM) for latent-variable PCFGs. It is on github . The slides from my Mathematics of Language 2017 talk are available here . A new book about Bayesian Analysis in Natural Language Processing is out ( website , hardcopy on Amazon ). Marco has developed a new AMR parser called AMREager and a new set of evaluation metrics for AMR . Publications Click here for a list Teaching Processing Formal and Natural Languages (INF2A). Course website (Autumn 2018; Autumn 2017; Autumn 2015). Topics in Natural Language Processing (INFR11113). Course website (Spring 2017). See also below. Lecture on linear classification at the Lisbon Machine Learning School (LxMLS) , July 2015. Topics in Natural Language Processing (INFR11113). Course website for 2016 (Spring 2015; Spring 2016). Course on PATH . Click here for a synopsis. Natural language processing is an application area in computer science, heavily supported by the industry with new applications emerging on a constant basis. The goal of this course is to give a different angle and look into natural language processing. We will explore basic concepts in computer science, machine learning, and statistics that make natural language processing such a rich area of research. You will learn how to use generic methods for application to specific problems you need to address in order to make use of natural language. As such, we will take a method-oriented view of NLP instead of an application-oriented one. Topics we will discuss include: basic probability and statistics used in NLP, structured prediction with log-linear models, Bayesian inference, finite state transducers, context-free grammars and other constructs, latent-variable modeling, basic concepts in learning theory. Hopefully, after taking the class, when using a generic NLP tool such as a part-of-speech tagger or a syntactic parser, you will be able to hypothesize how the tool generally works under the hood and why. This class can also assist you later in research in natural language processing, should you choose to pursue a PhD degree in the area. A tutorial about Spectral learning algorithms for NLP (NAACL, 2013). Similar tutorial with overlapping material at CMU (June, 2014). Seminar at Columbia - Bayesian analysis for NLP (Spring, 2013). A course at IBM about Probability and Structure in NLP (May, 2011). Students and Post-docs Maximin Coavoux (postdoc, 2018-) Matthieu Labeau (postdoc, 2018-) Shashi Narayan (postdoc, 2014-) Esma Balkr (PhD student, 2016-) Marco Damonte (PhD student, 2015-) Jiangming Liu (PhD student, 2017-; co-advised with Mirella Lapata) Nikos Papasarantopoulos (PhD student, 2016-) Joana Ribeiro (MPhil student, 2015-) John Torr (PhD student, 2015-; co-advised with Mark Steedman) Here is a group picture from summer 2018. Here is an older picture from summer 2017. Here is an older picture from summer 2016. Here is an even older picture from summer 2015. Here is a link to our group page that includes code, project and demo pages. Events Workshop about representation learning in NLP at ACL 2017 ( workshop's website ). Workshop about representation learning in NLP at ACL 2016 ( workshop's website ). Workshop about vector space modelling in NLP at NAACL 2015 ( workshop's website with post-workshop materials and pictures ). Code and Data L-PCFG models from our ACL 2016 paper about multilingual parsing with spectral estimation. CTREES - data from our EMNLP 2015 paper about conversation trees. Recipe data from our NAACL 2015 paper about event ordering in cooking recipes. dageem - code for unsupervised grammar induction using logistic normal prior. Link on github.com . Download zip . New version (1.01) is out on August 19, 2014. Contact information scohen [strudel] inf.ed.ac.uk 10 Crichton Street Informatics Forum 4.26 Edinburgh EH8 9AB United Kingdom Phone: +44 (0) 131 650 6542 
