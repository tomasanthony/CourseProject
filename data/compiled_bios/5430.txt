 Steve Renals Professor of Speech Technology, School of Informatics Member, Centre for Speech Technology Research Member, Institute of Language, Cognition, and Computation Director, Institute of Data Science and Engineering University of Edinburgh Home CSTR ILCC Research People & Projects Publications Teaching Bio Tweets Google Scholar Contact NST SUMMA PhD Programme in Data Science uDialogue CITIA Alan Turing Institute Quorate Cereproc New SUMMA project ! Scalable Understanding of Multilingual Media My slides from an invited talk on Towards an Interaction Baselayer at the Language Technology Industry Summit 2016 in Brussels. My slides from an invited talk at ASRU-2015 on Natural Speech Technology . My slides from an overview presentation at ASRU-2015 on the MGB Challenge . Recent papers : Pawel Swietojanski and Steve Renals, Differentiable Pooling for Unsupervised Acoustic Model Adaptation , submitted to IEEE/ACM TASLP, arXiv:1603.09630. Pawel Swietojanski, Jinyu Li, and Steve Renals, Learning Hidden Unit Contributions for Unsupervised Acoustic Model Adaptation , IEEE/ACM TASLP, 2016. Liang Lu, Lingpeng Kong, Chris Dyer, Noah A. Smith, and Steve Renals, Segmental Recurrent Neural Networks for End-to-end Speech Recognition , arXiv:1603:00223 Liang Lu and Steve Renals, Small-footprint Deep Neural Networks with Highway Connections for Speech Recognition , arXiv:1512.04280 Liang Lu, Xingxing Zhang, and Steve Renals, On training the recurrent neural network encoder-decoder for large vocabulary end-to-end speech recognition , ICASSP-2015. Pawel Swietojanski and Steve Renals, SAT-LHUC: Speaker adaptive training for learning hidden unit contributions , ICASSP-2016. P Bell, MJF Gales, T Hain, J Kilgour, P Lanchantin, X Liu, A McParland, S Renals, O Saz, M Wester, and P Woodland, The MGB Challenge: Evaluating multi-genre broadcast media recognition , ASRU-2015. Peter Bell and Steve Renals, A system for automatic alignment of broadcast media captions using weighted finite-state transducers , ASRU-2015. Ahmed Ali, Walid Magdi, Peter Bell, and Steve Renals, Multi-reference WER for evaluating ASR for languages with no orthographic rule , ASRU-2015. Liang Lu, Xingxing Zhang, Kyunghung Cho, and Steve Renals, A Study of the Recurrent Neural Network Encoder-Decoder for Large Vocabulary Speech Recognition , Interspeech-2015. Liang Lu and Steve Renals, Feature-space Speaker Adaptation for Probabilistic Linear Discriminant Analysis Acoustic Models , Interspeech-2015. Zhizheng Wu, Pawel Swietojanski, Christophe Veaux, Steve Renals, and Simon King, A study of speaker adaptation for DNN-based speech synthesis , Interspeech-2015. Peter Bell and Steve Renals, Complementary tasks for context-dependent deep neural network acoustic models , Interspeech-2015. Siva Reddy Gangireddy, Steve Renals, Yoshihiko Nankaku, and Akinobu Lee, Prosodically-enhanced Recurrent Neural Network Language Models , Interspeech-2015. Recent Best Paper Awards: Pawel Swietojanski and Steve Renals. Learning Hidden Unit Contributions for Unsupervised Speaker Adaptation of Neural Network Acoustic Models , IEEE SLT-2014. (Best paper) Liang Lu, Arnab Ghoshal, and Steve Renals. Acoustic Data-driven Pronunciation Lexicon for Large Vocabulary Speech Recognition , IEEE ASRU-2013. (Best paper) Pawel Swietojanski, Arnab Ghoshal, and Steve Renals. Unsupervised cross-lingual knowledge transfer in DNN-based LVCSR , IEEE SLT-2012. (Best student paper) Songfang Huang and Steve Renals. Power Law Discounting for N-Gram Language Models , IEEE ICASSP-2010. (Best student paper in speech technology) Research I'm interested in understanding human communication using machine learning and statistical models, and constructing systems that can recognize and interpret communication scenes. My research career is grounded in speech processing, and our approaches start from the signals. Speech Recognition and Synthesis How can we improve conversational speech recognition? How can we make speech synthesis more natural? We are looking at better speech recognition systems that are better adapted or normalised to new domains or speakers, that can be ported across languages, and that are robust to different acoustic environments. We are particularly interested in models based on deep neural networks, for both acoustic modelling and language modelling. Current research students in speech recognition and synthesis include Pawel Swietojanski , Siva Reddy Gangireddy , and Joachim Fainberg . I'm also working with Ben Krause on recurrent neural networks. Researchers working with me on speech recognition include Peter Bell and Liang Lu . In speech synthesis, I am trying to keep up with the great work of Simon King , Junichi Yamagishi , and their colleagues, as well as working with Korin Richmond on articulatory modelling. Read more... Multimodal Interaction Human communication is factored across more than one modality. The analysis and interpretation of multimodal interaction presents a number of challenges, ranging from ways to model multiple asynchronous streams of data to the construction of systems that can interpret aspects of multiparty human communication. A lot of this work is about augmenting communication in meetings - in the AMI and AMIDA Integrated Projects, and in the InEvent project. I work with Catherine Lai , Jonathan Kilgour , and Jean Carletta in these areas. And I try to keep up with Hiroshi Shimodaira 's work on synthesising conversational agents and social signals. Read more... Projects I'm principal investigator of the Natural Speech Technology , SUMMA , and uDialogue projects. Previous projects include the AMI and AMIDA Integrated Projects. Opportunities We are always looking for excellent research students: see the page about PhD opportunities at CSTR. I am not looking for visiting interns for the foreseeable future. Teaching This year I am teaching the Machine Learning Practical , and also Automatic Speech Recognition (ASR jointly with Hiroshi Shimodaira ). CSTR ILCC Informatics UoE Last edited: 2016-05-17T13:12:00Z (srenals) 
