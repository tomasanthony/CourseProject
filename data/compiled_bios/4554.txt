 Rob Jacob Robert J.K. Jacob Dept. of Computer Science Tufts University Halligan Hall 161 College Avenue Medford, MA 02155 U.S.A. Email: WWW: http://www.cs.tufts.edu/~jacob/ Phone: 617-627-2225 Fax: 617-627-2227 Office Hours: Normally Mondays, 3:15 p.m. Halligan 215 Background Robert Jacob is a Professor of Computer Science at Tufts University, where his research interests are new interaction modes and techniques and user interface software; his current work focuses on implicit brain-computer interfaces. He has been a visiting professor at the University College London Interaction Centre, Universite Paris-Sud, and the MIT Media Laboratory. Before coming to Tufts, he was in the Human-Computer Interaction Lab at the Naval Research Laboratory. He received his Ph.D. from Johns Hopkins University, and he is a member of the editorial board for the journal Human-Computer Interaction and a founding member for ACM Transactions on Computer-Human Interaction. He has served as Vice-President of ACM SIGCHI, Papers Co-Chair of the CHI and UIST conferences, and General Co-Chair of UIST and TEI. He was elected as a member of the ACM CHI Academy in 2007 and as an ACM Fellow in 2016. Current Research: Implicit Brain-Computer Interfaces The current focus in my research group is on a new generation of "implicit" brain-computer interfaces. They allow a computer to obtain and act on auxiliary inputs from its user without requiring explicit user action or attention. Brain-computer interaction has made dramatic progress, but its main application to date has been for physically disabled users. Our work in real-time measurement and machine learning classification of functional near infrared spectroscopy (fNIRS) brain data is allows to create, use, and study new kinds of implicit user interfaces based on brain measurement. We are using brain input as a way to obtain more information about the user and their context in an effortless and direct way from their brain activity. We then use it to adapt the user interface in real time. We are creating and studying these new user interfaces, with emphasis on domains where we can measure their efficacy. We are now also broadening this work to include other forms of lightweight, passive, real-time adaptive implicit interaction, based on physiological or other measurements. Our focus continues to be on the design of subtle and effective implicit interfaces that make judicious use of the measurements we can obtain. [General article] [Overview chapter] [More papers] Papers, Talks, News Papers with links to electronic versions of recent ones Talks and other presentations Professional activities Inducted as ACM Fellow 2016 Gave opening keynote at First Neuroadaptive Technology Conference NAT'17, Berlin, 2017 CHI 2016 paper on brain-computer interaction for music learning by Beste Yuksel et al. received Best Paper Award. Beste Yuksel's research on music learning reported in New Scientist IEEE Computer Special Issue on Physiological Computing, with Erin Solovey as guest co-editor, published October 2015 [Editors' introducton] [Contents] [Audio interview] Research featured in the Boston Globe (March 3, 2014), The Times (London), New York Post, and elsewhere. Video and article about our research featured in Tufts Now , also on WBUR's Radio Boston and CCTV America CHI 2014 paper on brain-computer interaction by Dan Afergan et al. received Best Paper Honorable Mention Award. Dan Afergan's research on brain-computer interfaces reported in New Scientist Evan Peck's research on brain-computer interfaces reported in New Scientist , ACM Tech News , and Discovery News . CHI 2012 paper on brain-computer interaction by Erin Solovey et al. received Best Paper Honorable Mention Award. This work was also covered by MIT Technology Review, extremetech.com , and many other places. Comment on future iPads in Huffington Post Comment on TV remote controls [also posted here] Still more comments, on the Spark radio show on CBC [podcast; segment starts around 0:06] [MP3, 53MB] Some comments on the legacy of Steve Jobs Mike Horn's work on tangible programming languages for children, at the Boston Museum of Science, reported on NECN TV [podcast]. Computerworld article [link] [local copy] discusses Reality-Based Interaction Elected to ACM CHI Academy 2007 [more info] (Photo courtesy of Ben Shneiderman) Some Previous Research Projects Reality-based Interaction: Understanding the Next Generation of User Interfaces [project] [CHI paper] [CHI workshop] Tangible Programming for children [Michael Horn] [project] [Robot Park] at Boston Museum of Science TUIMS: Tangible User Interface Management System [Orit Shaer] [paper] Courses Fall 2018 COMP 86 Object-Oriented Programming for Graphical User Interfaces Spring 2018 COMP 171 Human-Computer Interaction Ph.D. Alumni Beste Yuksel , University of San Francisco Dan Afergan , Google Inc. Evan Peck , Bucknell University Erin Solovey , Drexel University Audrey Girouard , Carleton University Leanne Hirshfield , Syracuse University Michael Horn , Northwestern University Michael Poor , Baylor University Orit Shaer , Wellesley College Georgios Christou , European University Cyprus Horn-yeu Shiaw, HCI Inc. Vildan Tanriverdi, IBM Leon Deligiannidis , Wentworth Institute of Technology Stephen Morrison, Intersystems Some Links Dept. of Computer Science HCI at Tufts School of Engineering Tufts University HCI Pioneers web page BostonCHILabs a consortium of Boston-area HCI universities and research groups Pictures of my family Miscellaneous photography and computer art Kathy's latest book (Group photo courtesy of Dan Afergan) 
